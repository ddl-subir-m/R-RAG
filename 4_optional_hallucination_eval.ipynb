{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daee71-0437-4884-8ce0-77314a9b5814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#restart the kernel after executing this cell\n",
    "! pip install pinecone-client==2.2.4 selfcheckgpt \n",
    "! sudo python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2245863-b091-4222-b70a-3a1c3987a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run RAG.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03dfde81-3e04-4752-9cf4-8009f945f63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "from selfcheckgpt.modeling_selfcheck import SelfCheckNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1972c82-7bcd-44e9-90cb-0b00a252af42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "selfcheck_nli = SelfCheckNLI(device=device) # set device to 'cuda' if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e74cca7-309c-48f0-8863-1fa2e0ef8e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, \n",
    "                  model='gpt-3.5-turbo-0613')\n",
    "\n",
    "conversation_openai = ConversationChain(\n",
    "        llm=chat,\n",
    "        memory=ConversationSummaryMemory(llm=chat),\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "# Function that returns the response from the RAG for the evaluation dataset\n",
    "def get_answers(question, n_samples:int=4):\n",
    "    # This function should return a list of 4 answers\n",
    "    # For example:\n",
    "    # return [\"Answer 1\", \"Answer 2\", \"Answer 3\", \"Answer 4\"]\n",
    "    samples = []\n",
    "\n",
    "    system_prompt, contexts = build_system_prompt(question, use_hyde=False)            \n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=question\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        response = conversation_openai.predict(input=messages)\n",
    "        samples.append(response)\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Assuming the existence of this scoring function\n",
    "def score_responses(passage, samples):\n",
    "    # This function should return a list of scores for each sentence in response1\n",
    "    # For example:\n",
    "    # return [0.9, 0.85, 0.95]  # Example scores for each sentence in response1\n",
    "    sentences = [sent.text.strip() for sent in nlp(passage).sents] # spacy sentence tokenization\n",
    "    sent_scores_nli = selfcheck_nli.predict(\n",
    "        sentences = sentences, # list of sentences\n",
    "        sampled_passages = samples, # list of sampled passages\n",
    "    )\n",
    "    return sent_scores_nli\n",
    "\n",
    "# Function to process each question\n",
    "def process_questions(row):\n",
    "    answers = get_answers(row['Question'])\n",
    "    first_answer = answers[0]\n",
    "    other_answers = answers[1:]\n",
    "    scores = score_responses(first_answer, other_answers)\n",
    "    median_score = pd.Series(scores).median() if len(scores) > 1 else scores[0]\n",
    "    return pd.DataFrame({\n",
    "        'Question': [row['Question']],\n",
    "        'Response': [first_answer],\n",
    "        'Scores': [scores],\n",
    "        'Median Score': [median_score]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9804824e-fcdc-4a01-9ffe-dde1d738e285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0        How can I track my order status on Rakuten?   \n",
      "1   What is Rakuten's return policy for electronics?   \n",
      "2  Can I change the shipping address after placin...   \n",
      "3      What payment methods are accepted on Rakuten?   \n",
      "4  Is it possible to cancel my order after it has...   \n",
      "\n",
      "                                            Response  \\\n",
      "0  To track your order status on Rakuten, you can...   \n",
      "1  Rakuten's return policy for electronics may va...   \n",
      "2  Yes, you can change the shipping address after...   \n",
      "3  On Rakuten, we accept Visa, American Express, ...   \n",
      "4  Yes, it is possible to cancel your order after...   \n",
      "\n",
      "                                              Scores  Median Score  \n",
      "0  [0.01224923444290956, 0.0009741231721515456, 0...      0.004522  \n",
      "1  [0.0001989066464981685, 0.0004948702019949754,...      0.016090  \n",
      "2  [0.0009182147526492676, 0.7618062297503153, 0....      0.042213  \n",
      "3  [0.026444549361864727, 0.000378673702167968, 0...      0.010493  \n",
      "4  [0.00214352000815173, 0.01014758087694645, 0.0...      0.036274  \n"
     ]
    }
   ],
   "source": [
    "# Example DataFrame with questions, testing on only 5 questions for now as this approach uses sampling multiple responses\n",
    "data = {\n",
    "    'Question': [\"How can I track my order status on Rakuten?\",\n",
    "            \"What is Rakuten's return policy for electronics?\",\n",
    "            \"Can I change the shipping address after placing my order?\",\n",
    "            \"What payment methods are accepted on Rakuten?\",\n",
    "            \"Is it possible to cancel my order after it has been shipped?\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Apply the function to each row in the DataFrame and concatenate the results\n",
    "hallucination_eval_df = pd.concat([process_questions(row) for index, row in df.iterrows()]).reset_index(drop=True)\n",
    "\n",
    "print(hallucination_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b02f63-3970-4130-ad84-5fa095cd1a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hallucination_eval_df.to_csv('hallucination_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f4aca-02b0-44b4-9ea5-d538d00fe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log this csv as an artifact to mlflow. \n",
    "# mlflow allows csvs to be logged as artifacts like so\n",
    "\n",
    "# Log CSV to MLflow\n",
    "# mlflow.log_artifact('hallucination_statistics.csv')"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
