{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daee71-0437-4884-8ce0-77314a9b5814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#restart the kernel after executing this cell\n",
    "! pip install pinecone-client==2.2.4 selfcheckgpt \n",
    "! sudo python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2245863-b091-4222-b70a-3a1c3987a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pinecone-client==2.2.4 in /home/domino/.local/lib/python3.10/site-packages (2.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.10.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/domino/.local/lib/python3.10/site-packages (from pinecone-client==2.2.4) (2.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.4) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/domino/.local/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%run RAG.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03dfde81-3e04-4752-9cf4-8009f945f63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "from selfcheckgpt.modeling_selfcheck import SelfCheckNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1972c82-7bcd-44e9-90cb-0b00a252af42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:830: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfCheck-NLI initialized to device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "selfcheck_nli = SelfCheckNLI(device=device) # set device to 'cuda' if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e74cca7-309c-48f0-8863-1fa2e0ef8e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, \n",
    "                  model='gpt-3.5-turbo-0613')\n",
    "\n",
    "conversation_openai = ConversationChain(\n",
    "        llm=chat,\n",
    "        memory=ConversationSummaryMemory(llm=chat),\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "# Function that returns the response from the RAG for the evaluation dataset\n",
    "def get_answers(question, n_samples:int=4):\n",
    "    # This function should return a list of 4 answers\n",
    "    # For example:\n",
    "    # return [\"Answer 1\", \"Answer 2\", \"Answer 3\", \"Answer 4\"]\n",
    "    samples = []\n",
    "\n",
    "    system_prompt, contexts = build_system_prompt(question, use_hyde=False)            \n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=question\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        response = conversation_openai.predict(input=messages)\n",
    "        samples.append(response)\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Assuming the existence of this scoring function\n",
    "def score_responses(passage, samples):\n",
    "    # This function should return a list of scores for each sentence in response1\n",
    "    # For example:\n",
    "    # return [0.9, 0.85, 0.95]  # Example scores for each sentence in response1\n",
    "    sentences = [sent.text.strip() for sent in nlp(passage).sents] # spacy sentence tokenization\n",
    "    sent_scores_nli = selfcheck_nli.predict(\n",
    "        sentences = sentences, # list of sentences\n",
    "        sampled_passages = samples, # list of sampled passages\n",
    "    )\n",
    "    return sent_scores_nli\n",
    "\n",
    "# Function to process each question\n",
    "def process_questions(row):\n",
    "    answers = get_answers(row['Question'])\n",
    "    first_answer = answers[0]\n",
    "    other_answers = answers[1:]\n",
    "    scores = score_responses(first_answer, other_answers)\n",
    "    median_score = pd.Series(scores).median() if len(scores) > 1 else scores[0]\n",
    "    return pd.DataFrame({\n",
    "        'Question': [row['Question']],\n",
    "        'Response': [first_answer],\n",
    "        'Scores': [scores],\n",
    "        'Median Score': [median_score]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9804824e-fcdc-4a01-9ffe-dde1d738e285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your documents have duplicate entries!  This will slow down calculation and may yield subpar results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0        How can I track my order status on Rakuten?   \n",
      "1   What is Rakuten's return policy for electronics?   \n",
      "2  Can I change the shipping address after placin...   \n",
      "3      What payment methods are accepted on Rakuten?   \n",
      "4  Is it possible to cancel my order after it has...   \n",
      "\n",
      "                                            Response  \\\n",
      "0  To track your order status on Rakuten, you can...   \n",
      "1  Rakuten's return policy for electronics may va...   \n",
      "2  Yes, you can change the shipping address after...   \n",
      "3  On Rakuten, we accept Visa, American Express, ...   \n",
      "4  Yes, it is possible to cancel your order after...   \n",
      "\n",
      "                                              Scores  Median Score  \n",
      "0  [0.01224923444290956, 0.0009741231721515456, 0...      0.004522  \n",
      "1  [0.0001989066464981685, 0.0004948702019949754,...      0.016090  \n",
      "2  [0.0009182147526492676, 0.7618062297503153, 0....      0.042213  \n",
      "3  [0.026444549361864727, 0.000378673702167968, 0...      0.010493  \n",
      "4  [0.00214352000815173, 0.01014758087694645, 0.0...      0.036274  \n"
     ]
    }
   ],
   "source": [
    "# Example DataFrame with questions, testing on only 5 questions for now as this approach uses sampling multiple responses\n",
    "data = {\n",
    "    'Question': [\"How can I track my order status on Rakuten?\",\n",
    "            \"What is Rakuten's return policy for electronics?\",\n",
    "            \"Can I change the shipping address after placing my order?\",\n",
    "            \"What payment methods are accepted on Rakuten?\",\n",
    "            \"Is it possible to cancel my order after it has been shipped?\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Apply the function to each row in the DataFrame and concatenate the results\n",
    "hallucination_eval_df = pd.concat([process_questions(row) for index, row in df.iterrows()]).reset_index(drop=True)\n",
    "\n",
    "print(hallucination_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b02f63-3970-4130-ad84-5fa095cd1a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hallucination_eval_df.to_csv('hallucination_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f4aca-02b0-44b4-9ea5-d538d00fe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log this csv as an artifact to mlflow. \n",
    "# mlflow allows csvs to be logged as artifacts like so\n",
    "\n",
    "# Log CSV to MLflow\n",
    "# mlflow.log_artifact('hallucination_statistics.csv')"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
